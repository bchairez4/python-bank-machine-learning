{"cells":[{"cell_type":"markdown","metadata":{},"source":["**<h1>Python Machine Learning Project</h1>**\n","\n","<h2>Created by Brian Chairez<h2>"]},{"cell_type":"markdown","metadata":{},"source":["This project will be utilizing <b><a href=\"https://pandas.pydata.org/\">pandas</a></b>, a software library used for data manipulation and analysis, and <b><a href=\"https://scikit-learn.org/stable/\">scikit-learn</a></b>, a software library that contains various classification, regression, and clustering algorithms for predictive data analysis."]},{"cell_type":"markdown","metadata":{},"source":["**<h3><u>Part 1 - Reading Data</u></h3>**"]},{"cell_type":"markdown","metadata":{},"source":["Using the <b>pandas.read_csv()</b> method, the provided csv files will be read in and loaded into dataframes. \n","Dataframes are a type of data structure similar to a 2-Dimensional table of rows and columns that can be filled with data of various types. \n","It is similar in concept to a spreadsheet as it is flexible and can be utilized to store and work with data.\n","\n","The <i>\"bank.csv\"</i> file will be the training dataframe while <i>\"bank-full.csv\"</i> will be the testing dataframe."]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["import pandas as pd\n","\n","trainDF = pd.read_csv('bank.csv', sep=';')\n","testDF = pd.read_csv('bank-full.csv', sep=';')"]},{"cell_type":"markdown","metadata":{},"source":["**<h3><u>Part 2 - Data Preprocessing</u></h3>**"]},{"cell_type":"markdown","metadata":{},"source":["Some of the features are categorical variables and will need to be turned into numbers using the <b>pandas.get_dummies()</b> method passing in <i>drop_first=True</i>."]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["trainDF = pd.get_dummies(trainDF, drop_first=True)\n","testDF = pd.get_dummies(testDF, drop_first=True)"]},{"cell_type":"markdown","metadata":{},"source":["The ['duration'] and ['y_yes'] feature will need to be droppped from both training and testing dataframes however the ['y_yes'] will become the target."]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["trainTarget = trainDF['y_yes']\n","trainDF = trainDF.drop(columns=['duration', 'y_yes'])\n","\n","testTarget = testDF['y_yes']\n","testDF = testDF.drop(columns=['duration', 'y_yes'])"]},{"cell_type":"markdown","metadata":{},"source":["Non-categorical features must be standardized in order to utilize K-Nearest Neighbor (KNN) and Support Vector Machine (SVM) classifiers. \n","\n","The specific features to be standardized are:\n","    <ul>\n","        <li>age</li> \n","        <li>campaign</li> \n","        <li>pdays</li>\n","        <li>previous</li>\n","        <li>emp.var.rate</li>\n","        <li>cons.price.idx</li>\n","        <li>cons.conf.idx</li>\n","        <li>euribor3m</li>\n","        <li>nr.employed</li>\n","    </ul>\n","\n","\n","This is done by subtracting the initial value with the mean and then dividing that result by the standard deviation of the respective feature:\n","\n","x' = ( x<sub>n</sub> - x̅ ) / σ\n","    "]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["# Training data standardization\n","for index, row in trainDF.iterrows():\n","  row['age'] = (row['age'] - trainDF['age'].mean())/trainDF['age'].std()\n","  row['campaign'] = (row['campaign'] - trainDF['campaign'].mean())/trainDF['campaign'].std()\n","  row['pdays'] = (row['pdays'] - trainDF['pdays'].mean())/trainDF['pdays'].std()\n","  row['previous'] = (row['previous'] - trainDF['previous'].mean())/trainDF['previous'].std()\n","  row['emp.var.rate'] = (row['emp.var.rate'] - trainDF['emp.var.rate'].mean())/trainDF['emp.var.rate'].std()\n","  row['cons.price.idx'] = (row['cons.price.idx'] - trainDF['cons.price.idx'].mean())/trainDF['cons.price.idx'].std()\n","  row['cons.conf.idx'] = (row['cons.conf.idx'] - trainDF['cons.conf.idx'].mean())/trainDF['cons.conf.idx'].std()\n","  row['euribor3m'] = (row['euribor3m'] - trainDF['euribor3m'].mean())/trainDF['euribor3m'].std()\n","  row['nr.employed'] = (row['nr.employed'] - trainDF['nr.employed'].mean())/trainDF['nr.employed'].std()\n","\n","# Test data standardization\n","for index, row in testDF.iterrows():\n","  row['age'] = (row['age'] - testDF['age'].mean())/testDF['age'].std()\n","  row['campaign'] = (row['campaign'] - testDF['campaign'].mean())/testDF['campaign'].std()\n","  row['pdays'] = (row['pdays'] - testDF['pdays'].mean())/testDF['pdays'].std()\n","  row['previous'] = (row['previous'] - testDF['previous'].mean())/testDF['previous'].std()\n","  row['emp.var.rate'] = (row['emp.var.rate'] - testDF['emp.var.rate'].mean())/testDF['emp.var.rate'].std()\n","  row['cons.price.idx'] = (row['cons.price.idx'] - testDF['cons.price.idx'].mean())/testDF['cons.price.idx'].std()\n","  row['cons.conf.idx'] = (row['cons.conf.idx'] - testDF['cons.conf.idx'].mean())/testDF['cons.conf.idx'].std()\n","  row['euribor3m'] = (row['euribor3m'] - testDF['euribor3m'].mean())/testDF['euribor3m'].std()\n","  row['nr.employed'] = (row['nr.employed'] - testDF['nr.employed'].mean())/testDF['nr.employed'].std()"]},{"cell_type":"markdown","metadata":{},"source":["**<h3><u>Part 3 - Model Fitting</u></h3>**"]},{"cell_type":"markdown","metadata":{},"source":["The <i>Guassian Naive Bayes</i>, <i>K-Nearest Neighbor (KNN)</i>, and <i>Support Vector Machine (SVM)</i> are the machine learning models this project will be utilizing from the scikit-learn library."]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC"]},{"cell_type":"markdown","metadata":{},"source":["The training data will be fit through instances of Naive Bayes, KNN, and SVM models by passing in the train dataframe and the target variable dataframe so each respective model can learn. \n","This will be useful as once the models are trained, they could each make predictions given the test dataframe which can be used to score the model."]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Gaussian Naive Bayes Score: 0.8545450131106147\n","K-Nearest Neighbors Score: 0.8871030397203069\n","Support Vector Machine Score: 0.8982470622511411\n"]}],"source":["# Gaussian Naive Bayes\n","gnb = GaussianNB()\n","gnb.fit(trainDF, trainTarget)\n","print('Gaussian Naive Bayes Score:', end=' ')\n","print(gnb.score(testDF, testTarget))\n","\n","# K-Nearest Neighbors\n","knn = KNeighborsClassifier(n_neighbors=3)\n","knn.fit(trainDF, trainTarget)\n","print('K-Nearest Neighbors Score:', end=' ')\n","print(knn.score(testDF, testTarget))\n","\n","# Support Vector Machine\n","svc = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n","svc.fit(trainDF, trainTarget)\n","print('Support Vector Machine Score:', end=' ')\n","print(svc.score(testDF, testTarget))"]},{"cell_type":"markdown","metadata":{},"source":["**<h3><u>Part 4 - Model Analysis</u></h3>**"]},{"cell_type":"markdown","metadata":{},"source":["The trained models can now be used to predict how it would map new inputs to their labels. This can be done using the <b>predict()</b> method from each respective model instance and passing in the test samples as the parameter."]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[],"source":["gnbPrediction = gnb.predict(testDF)\n","\n","knnPrediction = knn.predict(testDF)\n","\n","svmPrediction = svc.predict(testDF)"]},{"cell_type":"markdown","metadata":{},"source":["The <b>sklearn.metrics.confusion_matrix()</b> method can create a confusion matrix which is used to evaluate the accuracy of a classification by passing in the target values and the estimated targets as parameters.\n","\n","What the confusion matrix does is report the number of <i>true positives</i>, <i>false negatives</i>, <i>false positives</i>, and <i>true negatives</i> as such: \n","<table>\n","  <tr>\n","    <td>True Positive</td>\n","    <td>False Negative</td>\n","  </tr>\n","  <tr>\n","    <td>False Positive</td>\n","    <td>True Negative</td>\n","  </tr>\n","</table>"]},{"cell_type":"code","execution_count":58,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Gaussian Naive Bayes Confusion Matrix: \n","[[33020  3528]\n"," [ 2463  2177]]\n","\n","\n","K-Nearest Neighbors Confusion Matrix: \n","[[35274  1274]\n"," [ 3376  1264]]\n","\n","\n","Support Vector Machine Confusion Matrix: \n","[[36197   351]\n"," [ 3840   800]]\n","\n","\n"]}],"source":["from sklearn.metrics import confusion_matrix\n","\n","print('Gaussian Naive Bayes Confusion Matrix: ')\n","print(confusion_matrix(testTarget, gnbPrediction))\n","print('\\n')\n","\n","print('K-Nearest Neighbors Confusion Matrix: ')\n","print(confusion_matrix(testTarget, knnPrediction))\n","print('\\n')\n","\n","print('Support Vector Machine Confusion Matrix: ')\n","print(confusion_matrix(testTarget, svmPrediction))\n","print('\\n')"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
